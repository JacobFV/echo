{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('story_generation.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create timestamp and directory for this session\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = Path(f\"story_generation_{timestamp}\")\n",
    "save_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize Models\n",
    "def create_llms():\n",
    "    return {\n",
    "        'experience': ChatOpenAI(temperature=0.7),\n",
    "        'story': ChatOpenAI(temperature=0.9),\n",
    "        'reflection': ChatOpenAI(temperature=0.4),\n",
    "        'refinement': ChatOpenAI(temperature=0.7),\n",
    "        'latex': ChatOpenAI(temperature=0.3)\n",
    "    }\n",
    "\n",
    "def create_prompts():\n",
    "    return {\n",
    "        'experience': PromptTemplate(\n",
    "            input_variables=[\"context\"],\n",
    "            template=\"\"\"Given these story elements and memories:\n",
    "            \n",
    "            {context}\n",
    "            \n",
    "            Suggest deeply human experiences, emotions, and universal themes that relate to these elements. \n",
    "            Consider fundamental human experiences like love, loss, growth, fear, triumph, etc.\n",
    "            Be specific and draw meaningful connections.\"\"\"\n",
    "        ),\n",
    "        'story': PromptTemplate(\n",
    "            input_variables=[\"experiences\", \"related_memories\"],\n",
    "            template=\"\"\"Using these human experiences and thematic elements:\n",
    "            \n",
    "            {experiences}\n",
    "            \n",
    "            And drawing from these related memories and story elements:\n",
    "            \n",
    "            {related_memories}\n",
    "            \n",
    "            Craft a rich and engaging story segment that weaves these elements together.\n",
    "            Focus on vivid imagery, emotional resonance, and narrative flow.\"\"\"\n",
    "        ),\n",
    "        'reflection': PromptTemplate(\n",
    "            input_variables=[\"story\", \"experiences\"],\n",
    "            template=\"\"\"Reflect on this story segment and its themes:\n",
    "            \n",
    "            {story}\n",
    "            \n",
    "            Consider these underlying experiences and emotions:\n",
    "            {experiences}\n",
    "            \n",
    "            Analyze the narrative for:\n",
    "            1. Thematic consistency\n",
    "            2. Character development\n",
    "            3. Emotional resonance\n",
    "            4. Plot coherence\n",
    "            5. Symbolic depth\n",
    "            \n",
    "            Provide specific suggestions for deepening and enriching the narrative.\"\"\"\n",
    "        ),\n",
    "        'refinement': PromptTemplate(\n",
    "            input_variables=[\"story\", \"reflection\", \"experiences\"],\n",
    "            template=\"\"\"Enhance this story segment:\n",
    "            \n",
    "            {story}\n",
    "            \n",
    "            Based on this reflection:\n",
    "            {reflection}\n",
    "            \n",
    "            And maintaining these core experiences:\n",
    "            {experiences}\n",
    "            \n",
    "            Rewrite the segment with deeper emotional resonance, richer symbolism, and stronger narrative cohesion.\"\"\"\n",
    "        ),\n",
    "        'latex': PromptTemplate(\n",
    "            input_variables=[\"story\"],\n",
    "            template=\"\"\"Convert this story segment into properly formatted LaTeX:\n",
    "            \n",
    "            {story}\n",
    "            \n",
    "            Use appropriate LaTeX formatting for literary text, including proper paragraph breaks,\n",
    "            quotation marks, and any needed structural elements.\"\"\"\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Story Processing Functions\n",
    "class StoryProcessor:\n",
    "    def __init__(self, save_dir):\n",
    "        self.llms = create_llms()\n",
    "        self.prompts = create_prompts()\n",
    "        self.chains = self._create_chains()\n",
    "        self.save_dir = Path(save_dir)\n",
    "    \n",
    "    def _create_chains(self):\n",
    "        return {\n",
    "            name: LLMChain(llm=llm, prompt=self.prompts[name])\n",
    "            for name, llm in self.llms.items()\n",
    "        }\n",
    "    \n",
    "    def generate_experiences(self, context, chunk_id=None):\n",
    "        logging.info(\"Generating experiences\")\n",
    "        experiences = self.chains['experience'].run(context=context)\n",
    "        \n",
    "        if chunk_id is not None:\n",
    "            self._save_step(chunk_id, 'experiences', {'experiences': experiences})\n",
    "        return experiences\n",
    "    \n",
    "    def generate_initial_story(self, experiences, related_memories, chunk_id=None):\n",
    "        logging.info(\"Generating initial story\")\n",
    "        story = self.chains['story'].run(\n",
    "            experiences=experiences,\n",
    "            related_memories=related_memories\n",
    "        )\n",
    "        \n",
    "        if chunk_id is not None:\n",
    "            self._save_step(chunk_id, 'initial_story', {\n",
    "                'experiences': experiences,\n",
    "                'story': story\n",
    "            })\n",
    "        return story\n",
    "    \n",
    "    def generate_reflection(self, story, experiences, chunk_id=None):\n",
    "        logging.info(\"Generating reflection\")\n",
    "        reflection = self.chains['reflection'].run(\n",
    "            story=story,\n",
    "            experiences=experiences\n",
    "        )\n",
    "        \n",
    "        if chunk_id is not None:\n",
    "            self._save_step(chunk_id, 'reflection', {'reflection': reflection})\n",
    "        return reflection\n",
    "    \n",
    "    def refine_story(self, story, reflection, experiences, chunk_id=None):\n",
    "        logging.info(\"Refining story\")\n",
    "        refined = self.chains['refinement'].run(\n",
    "            story=story,\n",
    "            reflection=reflection,\n",
    "            experiences=experiences\n",
    "        )\n",
    "        \n",
    "        if chunk_id is not None:\n",
    "            self._save_step(chunk_id, 'refined_story', {\n",
    "                'original': story,\n",
    "                'reflection': reflection,\n",
    "                'refined': refined\n",
    "            })\n",
    "        return refined\n",
    "    \n",
    "    def convert_to_latex(self, story, chunk_id=None):\n",
    "        logging.info(\"Converting to LaTeX\")\n",
    "        latex = self.chains['latex'].run(story=story)\n",
    "        \n",
    "        if chunk_id is not None:\n",
    "            self._save_step(chunk_id, 'latex', {'latex': latex})\n",
    "        return latex\n",
    "    \n",
    "    def _save_step(self, chunk_id, step_name, data):\n",
    "        filepath = self.save_dir / f\"chunk_{chunk_id}_{step_name}.json\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Interactive Story Development\n",
    "# Initialize processor\n",
    "processor = StoryProcessor(save_dir)\n",
    "\n",
    "# Example usage for a single chunk\n",
    "chunk_id = 0  # You can change this for different chunks\n",
    "\n",
    "# You can now use these functions interactively\n",
    "context = \"\"\"Your story context here\"\"\"\n",
    "related_memories = \"\"\"Your related memories here\"\"\"\n",
    "\n",
    "# Generate experiences\n",
    "experiences = processor.generate_experiences(context, chunk_id)\n",
    "print(\"Generated experiences:\", experiences)\n",
    "\n",
    "# Generate initial story\n",
    "initial_story = processor.generate_initial_story(experiences, related_memories, chunk_id)\n",
    "print(\"\\nInitial story:\", initial_story)\n",
    "\n",
    "# Generate reflection\n",
    "reflection = processor.generate_reflection(initial_story, experiences, chunk_id)\n",
    "print(\"\\nReflection:\", reflection)\n",
    "\n",
    "# Refine story\n",
    "refined_story = processor.refine_story(initial_story, reflection, experiences, chunk_id)\n",
    "print(\"\\nRefined story:\", refined_story)\n",
    "\n",
    "# Convert to LaTeX\n",
    "latex_version = processor.convert_to_latex(refined_story, chunk_id)\n",
    "print(\"\\nLaTeX version:\", latex_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Batch Processing (Optional)\n",
    "def process_all_documents(processor, all_docs):\n",
    "    output_file = io.StringIO()\n",
    "    \n",
    "    for current_idx, current_doc in enumerate(all_docs):\n",
    "        logging.info(f\"Processing document chunk {current_idx + 1}/{len(all_docs)}\")\n",
    "        \n",
    "        current_content = current_doc.page_content\n",
    "        related_docs = [doc for doc in all_docs[:current_idx]]\n",
    "        related_memories = \"\\n\\n\".join([doc.page_content for doc in related_docs])\n",
    "        \n",
    "        # Full generation pipeline\n",
    "        experiences = processor.generate_experiences(current_content, current_idx)\n",
    "        initial_story = processor.generate_initial_story(experiences, related_memories, current_idx)\n",
    "        reflection = processor.generate_reflection(initial_story, experiences, current_idx)\n",
    "        refined_story = processor.refine_story(initial_story, reflection, experiences, current_idx)\n",
    "        latex_text = processor.convert_to_latex(refined_story, current_idx)\n",
    "        \n",
    "        output_file.write(latex_text + \"\\n\\n\")\n",
    "    \n",
    "    final_latex = output_file.getvalue()\n",
    "    with open(processor.save_dir / \"complete_story.tex\", 'w') as f:\n",
    "        f.write(final_latex)\n",
    "    \n",
    "    return final_latex\n",
    "\n",
    "# Example usage:\n",
    "# final_story = process_all_documents(processor, all_docs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
