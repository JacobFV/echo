{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "\n",
    "# Import necessary libraries\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import logging\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('story_generation.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create timestamped directory for saving outputs\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = Path(f\"story_generation_{timestamp}\")\n",
    "save_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load and Prepare Documents\n",
    "\n",
    "# Load all markdown files from chapters directory\n",
    "loader = DirectoryLoader('./chapters', glob=\"**/*.md\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Add counter index to each document\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['index'] = i\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Preserve the original document index in the chunks\n",
    "for text in texts:\n",
    "    text.metadata['doc_index'] = text.metadata['index']\n",
    "\n",
    "# Add chunk index and master index to each text\n",
    "master_index = 0\n",
    "for doc_index in range(max(text.metadata['doc_index'] for text in texts) + 1):\n",
    "    # Get all chunks for this document\n",
    "    doc_chunks = [t for t in texts if t.metadata['doc_index'] == doc_index]\n",
    "    \n",
    "    # Add chunk index within document\n",
    "    for chunk_idx, chunk in enumerate(doc_chunks):\n",
    "        chunk.metadata['chunk_index'] = chunk_idx\n",
    "        chunk.metadata['master_index'] = master_index\n",
    "        master_index += 1\n",
    "\n",
    "# Create embeddings and store in Chroma vector database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "# Create retriever interface\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": len(texts)}  # Retrieve all texts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Initialize Language Models and Prompts\n",
    "\n",
    "# Initialize LLMs with different temperatures for different creative needs\n",
    "experience_llm = ChatOpenAI(temperature=0.7)\n",
    "story_llm = ChatOpenAI(temperature=0.9)\n",
    "reflection_llm = ChatOpenAI(temperature=0.4)\n",
    "refinement_llm = ChatOpenAI(temperature=0.7)\n",
    "latex_llm = ChatOpenAI(temperature=0.3)\n",
    "\n",
    "# Create prompts for each stage\n",
    "experience_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"\"\"Given these story elements and memories:\n",
    "\n",
    "{context}\n",
    "\n",
    "Suggest deeply human experiences, emotions, and universal themes that relate to these elements. \n",
    "Consider fundamental human experiences like love, loss, growth, fear, triumph, etc.\n",
    "Be specific and draw meaningful connections.\"\"\"\n",
    ")\n",
    "\n",
    "story_prompt = PromptTemplate(\n",
    "    input_variables=[\"experiences\", \"related_memories\"],\n",
    "    template=\"\"\"Using these human experiences and thematic elements:\n",
    "\n",
    "{experiences}\n",
    "\n",
    "And drawing from these related memories and story elements:\n",
    "\n",
    "{related_memories}\n",
    "\n",
    "Craft a rich and engaging story segment that weaves these elements together.\n",
    "Focus on vivid imagery, emotional resonance, and narrative flow.\"\"\"\n",
    ")\n",
    "\n",
    "reflection_prompt = PromptTemplate(\n",
    "    input_variables=[\"story\", \"experiences\"],\n",
    "    template=\"\"\"Reflect on this story segment and its themes:\n",
    "\n",
    "{story}\n",
    "\n",
    "Consider these underlying experiences and emotions:\n",
    "{experiences}\n",
    "\n",
    "Analyze the narrative for:\n",
    "1. Thematic consistency\n",
    "2. Character development\n",
    "3. Emotional resonance\n",
    "4. Plot coherence\n",
    "5. Symbolic depth\n",
    "\n",
    "Provide specific suggestions for deepening and enriching the narrative.\"\"\"\n",
    ")\n",
    "\n",
    "refinement_prompt = PromptTemplate(\n",
    "    input_variables=[\"story\", \"reflection\", \"experiences\"],\n",
    "    template=\"\"\"Enhance this story segment:\n",
    "\n",
    "{story}\n",
    "\n",
    "Based on this reflection:\n",
    "{reflection}\n",
    "\n",
    "And maintaining these core experiences:\n",
    "{experiences}\n",
    "\n",
    "Rewrite the segment with deeper emotional resonance, richer symbolism, and stronger narrative cohesion.\"\"\"\n",
    ")\n",
    "\n",
    "latex_prompt = PromptTemplate(\n",
    "    input_variables=[\"story\"],\n",
    "    template=\"\"\"Convert this story segment into properly formatted LaTeX:\n",
    "\n",
    "{story}\n",
    "\n",
    "Use appropriate LaTeX formatting for literary text, including proper paragraph breaks,\n",
    "quotation marks, and any needed structural elements.\"\"\"\n",
    ")\n",
    "\n",
    "# Create chains for each stage\n",
    "experience_chain = LLMChain(llm=experience_llm, prompt=experience_prompt)\n",
    "story_chain = LLMChain(llm=story_llm, prompt=story_prompt)\n",
    "reflection_chain = LLMChain(llm=reflection_llm, prompt=reflection_prompt)\n",
    "refinement_chain = LLMChain(llm=refinement_llm, prompt=refinement_prompt)\n",
    "latex_chain = LLMChain(llm=latex_llm, prompt=latex_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Process Documents through Experience Chain\n",
    "\n",
    "# Initialize output containers\n",
    "experiences_list = []\n",
    "\n",
    "# Get all documents (in order)\n",
    "all_docs = retriever.get_relevant_documents(\"\")\n",
    "\n",
    "# Create a mapping from doc content to index\n",
    "doc_indices = {doc.page_content: idx for idx, doc in enumerate(all_docs)}\n",
    "\n",
    "# Process each document chunk to generate experiences\n",
    "for current_idx, current_doc in enumerate(all_docs):\n",
    "    logging.info(f\"Experience Chain: Processing document {current_idx + 1}/{len(all_docs)}\")\n",
    "    \n",
    "    current_content = current_doc.page_content\n",
    "    \n",
    "    # Only retrieve documents that came before this one\n",
    "    related_docs = [doc for doc in all_docs if doc_indices[doc.page_content] < current_idx]\n",
    "    related_memories = \"\\n\\n\".join([doc.page_content for doc in related_docs])\n",
    "    \n",
    "    # Combine current content with related memories for context\n",
    "    full_context = f\"Current Memory:\\n{current_content}\\n\\nRelated Memories:\\n{related_memories}\"\n",
    "    \n",
    "    # Generate human experiences\n",
    "    experiences = experience_chain.run(context=full_context)\n",
    "    experiences_list.append(experiences)\n",
    "    \n",
    "    # Save experiences to file\n",
    "    with open(save_dir / f\"doc_{current_idx}_experiences.txt\", 'w') as f:\n",
    "        f.write(experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Process Documents through Story Chain\n",
    "\n",
    "# Initialize output container\n",
    "stories_list = []\n",
    "\n",
    "# Process each experiences to generate initial stories\n",
    "for current_idx, experiences in enumerate(experiences_list):\n",
    "    logging.info(f\"Story Chain: Processing document {current_idx + 1}/{len(experiences_list)}\")\n",
    "    \n",
    "    # Get related memories (only prior docs)\n",
    "    related_docs = [doc for idx, doc in enumerate(all_docs) if idx < current_idx]\n",
    "    related_memories = \"\\n\\n\".join([doc.page_content for doc in related_docs])\n",
    "    \n",
    "    # Generate story\n",
    "    story = story_chain.run(experiences=experiences, related_memories=related_memories)\n",
    "    stories_list.append(story)\n",
    "    \n",
    "    # Save initial story to file\n",
    "    with open(save_dir / f\"doc_{current_idx}_initial_story.txt\", 'w') as f:\n",
    "        f.write(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Process Stories through Reflection Chain\n",
    "\n",
    "# Initialize output container\n",
    "reflections_list = []\n",
    "\n",
    "# Process each story to generate reflections\n",
    "for current_idx, story in enumerate(stories_list):\n",
    "    logging.info(f\"Reflection Chain: Processing story {current_idx + 1}/{len(stories_list)}\")\n",
    "    \n",
    "    experiences = experiences_list[current_idx]\n",
    "    \n",
    "    # Generate reflection\n",
    "    reflection = reflection_chain.run(story=story, experiences=experiences)\n",
    "    reflections_list.append(reflection)\n",
    "    \n",
    "    # Save reflection to file\n",
    "    with open(save_dir / f\"doc_{current_idx}_reflection.txt\", 'w') as f:\n",
    "        f.write(reflection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Process Stories through Refinement Chain\n",
    "\n",
    "# Initialize output container\n",
    "refined_stories_list = []\n",
    "\n",
    "# Refine each story based on reflections\n",
    "for current_idx, story in enumerate(stories_list):\n",
    "    logging.info(f\"Refinement Chain: Processing story {current_idx + 1}/{len(stories_list)}\")\n",
    "    \n",
    "    reflection = reflections_list[current_idx]\n",
    "    experiences = experiences_list[current_idx]\n",
    "    \n",
    "    # Refine the story\n",
    "    refined_story = refinement_chain.run(\n",
    "        story=story,\n",
    "        reflection=reflection,\n",
    "        experiences=experiences\n",
    "    )\n",
    "    refined_stories_list.append(refined_story)\n",
    "    \n",
    "    # Save refined story to file\n",
    "    with open(save_dir / f\"doc_{current_idx}_refined_story.txt\", 'w') as f:\n",
    "        f.write(refined_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Convert Refined Stories to LaTeX\n",
    "\n",
    "# Initialize output container\n",
    "latex_output = io.StringIO()\n",
    "\n",
    "# Convert each refined story to LaTeX\n",
    "for current_idx, refined_story in enumerate(refined_stories_list):\n",
    "    logging.info(f\"LaTeX Conversion: Processing refined story {current_idx + 1}/{len(refined_stories_list)}\")\n",
    "    \n",
    "    # Convert to LaTeX\n",
    "    latex_text = latex_chain.run(story=refined_story)\n",
    "    \n",
    "    # Save LaTeX to individual file\n",
    "    with open(save_dir / f\"doc_{current_idx}_story.tex\", 'w') as f:\n",
    "        f.write(latex_text)\n",
    "    \n",
    "    # Append to final LaTeX output\n",
    "    latex_output.write(latex_text + \"\\n\\n\")\n",
    "\n",
    "# Save the complete LaTeX document\n",
    "final_latex = latex_output.getvalue()\n",
    "with open(save_dir / \"complete_story.tex\", 'w') as f:\n",
    "    f.write(final_latex)\n",
    "\n",
    "logging.info(\"Story generation complete\")\n",
    "print(\"Generated LaTeX Story:\")\n",
    "print(final_latex)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
